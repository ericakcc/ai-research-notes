{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 â€” Train MDN-RNN (Memory Model M)\n",
    "\n",
    "Train the MDN-RNN to predict next-step latent vectors given current z and action.\n",
    "\n",
    "**Prerequisites:**\n",
    "1. Train VAE (notebook 02)\n",
    "2. Run `scripts/encode_rollouts.py` to generate encoded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "from src.config import Config\n",
    "from src.train_rnn import train_rnn\n",
    "\n",
    "config = Config()\n",
    "if torch.backends.mps.is_available():\n",
    "    config.device = \"mps\"\n",
    "print(f\"Device: {config.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MDN-RNN\n",
    "encoded_dir = Path.cwd().parent / \"datasets\" / \"encoded\"\n",
    "model = train_rnn(config.rnn, encoded_dir, device=config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual next z\n",
    "from src.rnn_dataset import RNNDataset\n",
    "\n",
    "dataset = RNNDataset(encoded_dir, sequence_length=config.rnn.sequence_length)\n",
    "z_input, actions, z_target = dataset[0]\n",
    "z_input = z_input.unsqueeze(0).to(config.device)\n",
    "actions = actions.unsqueeze(0).to(config.device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pi, mu, sigma, _ = model(z_input, actions)\n",
    "\n",
    "# Use the most probable mixture component's mean as prediction\n",
    "best_comp = pi[:, :, :, 0].argmax(dim=2)  # (1, T)\n",
    "pred_z = mu[0, torch.arange(mu.shape[1]), best_comp[0], :].cpu().numpy()\n",
    "actual_z = z_target.numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.plot(actual_z[:, i], label=\"actual\", alpha=0.7)\n",
    "    ax.plot(pred_z[:, i], label=\"predicted\", alpha=0.7)\n",
    "    ax.set_title(f\"z dim {i}\")\n",
    "    ax.legend(fontsize=8)\n",
    "plt.suptitle(\"MDN-RNN: Predicted vs Actual z\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dream: autoregressive generation\n",
    "# Start from a real z, then let the RNN dream forward\n",
    "from src.vae import ConvVAE\n",
    "\n",
    "vae = ConvVAE(latent_dim=config.vae.latent_dim)\n",
    "vae_ckpt = Path.cwd().parent / config.vae.checkpoint_dir / \"vae_final.pt\"\n",
    "vae.load_state_dict(torch.load(vae_ckpt, map_location=config.device, weights_only=True))\n",
    "vae.to(config.device).eval()\n",
    "\n",
    "# Seed with real data\n",
    "z_t = z_input[:, 0:1, :]  # (1, 1, latent_dim)\n",
    "hidden = model.init_hidden(1, torch.device(config.device))\n",
    "dream_frames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(50):\n",
    "        # Decode current z to image\n",
    "        frame = vae.decoder(z_t.squeeze(1))  # (1, 3, 64, 64)\n",
    "        dream_frames.append(frame.squeeze().cpu().permute(1, 2, 0).numpy())\n",
    "\n",
    "        # Random action\n",
    "        a_t = torch.randn(1, 1, 3).to(config.device) * 0.3\n",
    "        pi, mu, sigma, hidden = model(z_t, a_t, hidden)\n",
    "\n",
    "        # Sample from most likely component\n",
    "        best = pi[0, 0, :, 0].argmax()\n",
    "        z_t = mu[:, :, best, :] + sigma[:, :, best, :] * torch.randn_like(\n",
    "            sigma[:, :, best, :]\n",
    "        )\n",
    "\n",
    "fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = i * 2\n",
    "    if idx < len(dream_frames):\n",
    "        ax.imshow(np.clip(dream_frames[idx], 0, 1))\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"t={idx}\")\n",
    "plt.suptitle(\"MDN-RNN Dream Sequence\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
